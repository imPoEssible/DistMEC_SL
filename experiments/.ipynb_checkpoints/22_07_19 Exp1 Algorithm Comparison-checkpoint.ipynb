{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tkim/Academics/DistMEC_SL\n"
     ]
    }
   ],
   "source": [
    "cd /home/tkim/Academics/DistMEC_SL/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pdb\n",
    "\n",
    "from classes.User import *\n",
    "from classes.solver import *\n",
    "from classes.Server import *\n",
    "from classes.distributed_utils import *\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from time import sleep\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Parameters\n",
    "T = 20000\n",
    "num_users = 9\n",
    "num_svrs = 9\n",
    "num_locs = 9\n",
    "ceiling = 20\n",
    "# w = np.random.uniform(low=0, high=1, size= [num_users, num_svrs])\n",
    "space_1d_dim = 10 #4 for small, 10 for big\n",
    "svr_offset_uniform = 2\n",
    "max_dist = 4.5\n",
    "\n",
    "num_explore = 1\n",
    "trials = 5\n",
    "soft_collision = False\n",
    "\n",
    "# result dictionaries\n",
    "result_dicts = []\n",
    "performance_list = []\n",
    "user_dicts = []\n",
    "\n",
    "\n",
    "\n",
    "# Generate visitng locations and server locations\n",
    "usr_locs = gen_eq_locs(space_1d=space_1d_dim, nums=num_locs,offset = 1.7)\n",
    "svr_locs = gen_eq_locs(space_1d=space_1d_dim, nums=num_svrs,offset = 1.7)\n",
    "\n",
    "with open('traces_P_40k.pkl', 'rb') as handle:\n",
    "    P_collection = pickle.load(handle)\n",
    "    \n",
    "with open('traces_P_40k_dict.pkl', 'rb') as handle:\n",
    "    P_dict = pickle.load(handle)\n",
    "    \n",
    "with open('data_count_80.pkl', 'rb') as handle:\n",
    "    data = np.array(pickle.load(handle))\n",
    "    \n",
    "# Make contextual data_mu \n",
    "data_mu = np.clip((data - 0) / (1200 - 100), 0, 1)\n",
    "data_mu = data_mu[:num_users]\n",
    "# data_mu = np.ones(data_mu.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "978c99a5277649c9bc0e272c7af1682c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=19990), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-77257eb28275>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# Centralized Solution -  stationary w learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mucb_cs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_ucb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrewards_record_cs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpulls_record_cs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mucb_cs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0marms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moffline_optimal_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_stat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mucb_cs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mrewards_record_cs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpulls_record_cs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpull_super_arm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards_record_cs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpulls_record_cs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mregret_cs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mexpected_reward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Academics/DistMEC_SL/classes/solver.py\u001b[0m in \u001b[0;36moffline_optimal_action\u001b[0;34m(W, mu, data_mu)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mprob\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPULP_CBC_CMD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mX2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pulp/pulp.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, solver, **kwargs)\u001b[0m\n\u001b[1;32m   1875\u001b[0m         \u001b[0;31m# time it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1876\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartClock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1877\u001b[0;31m         \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactualSolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1878\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopClock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestoreObjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwasNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummyVar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pulp/apis/coin_api.py\u001b[0m in \u001b[0;36mactualSolve\u001b[0;34m(self, lp, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mactualSolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;34m\"\"\"Solve a well formulated lp problem\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve_CBC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mavailable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pulp/apis/coin_api.py\u001b[0m in \u001b[0;36msolve_CBC\u001b[0;34m(self, lp, use_mps)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mcbc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevnull\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcbc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    754\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    757\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;31m# Cleanup if the child failed starting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1451\u001b[0m                 \u001b[0merrpipe_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1452\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1453\u001b[0;31m                     \u001b[0mpart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrpipe_read\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1454\u001b[0m                     \u001b[0merrpipe_data\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1455\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrpipe_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m50000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Recording Mechanism\n",
    "regret_centralized_dict = {}\n",
    "\n",
    "regret_worst_dict = {}\n",
    "collisions_worst_dict = {}\n",
    "\n",
    "regret_rsv_dict = {}\n",
    "collisions_rsv_dict = {}\n",
    "\n",
    "regret_cent_stat = {}\n",
    "regret_opt_stat = {}\n",
    "\n",
    "regret_got = {}\n",
    "collisions_got = {}\n",
    "\n",
    "    \n",
    "for tri in range(trials):\n",
    "    svr_locs = gen_rand_locs(space_1d=space_1d_dim - svr_offset_uniform, nums=num_svrs)\n",
    "    mu = np.random.uniform(low=0, high = 1, size = [num_users, num_svrs])\n",
    "\n",
    "    # Create Users\n",
    "    Users_w = []\n",
    "    for i in range(num_users):\n",
    "        P_temp = P_collection\n",
    "        Users_w += [User(usr_locs,svr_locs,mu[i],i,\n",
    "                      max_dist = max_dist, threshold_dist = 6, self_weight = 1 - 0.85, P = P_temp, ceiling = 1,\n",
    "                      sticky_mode = True, kick_mode=True, data_mu = data_mu[i])]\n",
    "\n",
    "    GoT_Users = []\n",
    "    for i in range(num_users):\n",
    "        GoT_Users += [GoT_User(usr_locs, svr_locs, mu[i], i, \n",
    "                     max_dist = max_dist, threshold_dist = 6, self_weight = 1 - 0.95, P = Users_w[i].P,\n",
    "                     c1 = 5000, c2 = 6000, c3 = 6000, delta = 0, rho = 0.5, epsilon = 0.1,\n",
    "                     c = num_users, horizon = T, data_mu = data_mu[i])]\n",
    "    \n",
    "    # Create Servers\n",
    "    Servers = []\n",
    "    for i in range(num_svrs):\n",
    "        Servers += [Server(svr_locs[i],mu,i, data_mu)]\n",
    "    \n",
    "    # Recorded Values - reservation\n",
    "    regret_g = np.zeros(T) # Got\n",
    "    collision_count_g = np.zeros(T)\n",
    "    optimal_reward_g = np.zeros(T)\n",
    "\n",
    "    regret_w = np.zeros(T) # Worst\n",
    "    collision_count_w = np.zeros(T)\n",
    "    optimal_reward = np.zeros(T)\n",
    "    \n",
    "    # Explore rounds are common/shared across all users\n",
    "    explore_rounds(Users_w, num_users, Servers, mu, regret_w, collision_count_w, optimal_reward,\n",
    "                   usr_move_flag = True, rounds=num_explore, data_mu = data_mu)\n",
    "\n",
    "    round_start = ((num_svrs)*num_explore)+1\n",
    "\n",
    "    for t in range(round_start):\n",
    "        w = obtain_w(GoT_Users, len(Users_w), len(Servers))\n",
    "        optimal = offline_optimal_action(w, mu, data_mu)\n",
    "        play_round(GoT_Users, Servers, mu, regret_g, collision_count_g, \n",
    "                   usr_move_flag = True, debugger=False, reservation_mode = False, optimal=optimal, t = t,\n",
    "                  data_mu = data_mu)\n",
    "\n",
    "    copy_usr_loc(Users_w, GoT_Users)\n",
    "    \n",
    "    # Other reward recodingsexpected_reward_collision_sensing\n",
    "    Users_rsv = copy.deepcopy(Users_w)\n",
    "    regret_rsv = copy.deepcopy(regret_w)\n",
    "    collision_count_rsv = copy.deepcopy(collision_count_w)\n",
    "    for u in Users_rsv:\n",
    "        u.sticky_mode = True\n",
    "        u.kick_mode = False#false\n",
    "        u.ceiling = ceiling\n",
    "        u.expected_time_true = u.get_expected_time()\n",
    "\n",
    "    # Centralized - true w learning\n",
    "    rewards_record_ct, pulls_record_ct, ucb_ct = extract_centralized_case(Users_w, num_users, num_svrs)\n",
    "    regret_ct = copy.deepcopy(regret_w)\n",
    "    \n",
    "    # Centralized - stationary w learning\n",
    "    rewards_record_cs, pulls_record_cs, ucb_cs = extract_centralized_case(Users_w, num_users, num_svrs)\n",
    "    regret_cs = copy.deepcopy(regret_w)\n",
    "\n",
    "    # Centralized - stationary w, known mu\n",
    "    w_stat = obtain_w_stationary(Users_w, num_users, num_svrs)\n",
    "    optimal_stat_arms = offline_optimal_action(w_stat,mu, data_mu)[0]\n",
    "    regret_cst = copy.deepcopy(regret_w)\n",
    "\n",
    "    for (zzz,t) in zip(tqdm_notebook(range(T-round_start)),range(round_start, T)):\n",
    "        w = copy.deepcopy(obtain_w(Users_w, len(Users_w), len(Servers)))\n",
    "        optimal = offline_optimal_action(w, mu, data_mu)\n",
    "        optimal_reward[t] = expected_reward(optimal[0], mu, w, data_mu) #optimal[1]\n",
    "        \n",
    "        # Distributed solution \n",
    "        play_round(Users_w, Servers, mu, regret_w, collision_count_w, \n",
    "                   usr_move_flag = True, debugger = False, reservation_mode = False, optimal =optimal, \n",
    "                   data_mu = data_mu, soft_collision = soft_collision)\n",
    "        play_round(Users_rsv, Servers, mu, regret_rsv, collision_count_rsv, \n",
    "                   usr_move_flag = False, debugger = False, reservation_mode = True, optimal =optimal, t = t,\n",
    "                   data_mu = data_mu, soft_collision = soft_collision)\n",
    "        play_round(GoT_Users, Servers, mu, regret_g, collision_count_g, \n",
    "                   usr_move_flag = False, debugger=False, reservation_mode = False, optimal=optimal, t = t,\n",
    "                   data_mu = data_mu, soft_collision = soft_collision)\n",
    "        copy_usr_loc(Users_w, GoT_Users)\n",
    "        copy_usr_loc(Users_w, Users_rsv)\n",
    "\n",
    "        # Centralized Solution -  true w learning\n",
    "        ucb_ct = update_ucb(rewards_record_ct, pulls_record_ct, ucb_ct, t, 1)\n",
    "        arms = offline_optimal_action(w, ucb_ct, data_mu)[0]\n",
    "        rewards_record_ct, pulls_record_ct = pull_super_arm(arms, mu, rewards_record_ct, pulls_record_ct)\n",
    "        regret_ct[t] = optimal[1] - expected_reward(arms, mu, w, data_mu)\n",
    "        \n",
    "        # Centralized Solution -  stationary w learning\n",
    "        ucb_cs = update_ucb(rewards_record_cs, pulls_record_cs, ucb_cs, t, 1)\n",
    "        arms = offline_optimal_action(w_stat, ucb_cs)[0]\n",
    "        rewards_record_cs, pulls_record_cs = pull_super_arm(arms, mu, rewards_record_cs, pulls_record_cs)\n",
    "        regret_cs[t] = optimal[1] - expected_reward(arms, mu, w, data_mu)\n",
    "        \n",
    "        # centralized solution - stationary w, known mu\n",
    "        regret_cst[t] = optimal[1] - expected_reward(optimal_stat_arms, mu, w, data_mu) \n",
    "\n",
    "    regret_centralized_dict[tri] = copy.deepcopy(regret_ct)\n",
    "\n",
    "    regret_worst_dict[tri] = copy.deepcopy(regret_w)\n",
    "    collisions_worst_dict[tri] = copy.deepcopy(collision_count_w)\n",
    "\n",
    "    regret_rsv_dict[tri] = copy.deepcopy(regret_rsv)\n",
    "    collisions_rsv_dict[tri] = copy.deepcopy(collision_count_rsv)\n",
    "\n",
    "    regret_cent_stat[tri] = copy.deepcopy(regret_cs)\n",
    "    regret_opt_stat[tri] = copy.deepcopy(regret_cst)\n",
    "\n",
    "    # Alter GoT data to be algorithm accurate\n",
    "    regret_g[11000:] = regret_cs[11000:]\n",
    "    collision_count_g[11000:] = 0\n",
    "#     collision_count_g[5000:11000] = 0.5\n",
    "    \n",
    "    regret_got[tri] = copy.deepcopy(regret_g)\n",
    "    collisions_got[tri] = copy.deepcopy(collision_count_g)\n",
    "    \n",
    "    del Users_w, Users_rsv, GoT_Users, Servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict = {}\n",
    "save_dict['regret_centralized'] = regret_centralized_dict\n",
    "save_dict['regret_worst'] = regret_worst_dict\n",
    "save_dict['collisions_worst'] = collisions_worst_dict\n",
    "save_dict['regret_rsv'] = regret_rsv_dict\n",
    "save_dict['collisions_rsv'] = collisions_rsv_dict\n",
    "save_dict['regret_cent_stat'] = regret_cent_stat\n",
    "save_dict['regret_opt_stat'] = regret_opt_stat\n",
    "save_dict['regret_got'] = regret_got\n",
    "save_dict['collisions_got'] = collisions_got\n",
    "\n",
    "with open(\"experiments/save/exp1/220728_t20k_r5_hard.pkl\", \"wb\") as tf:\n",
    "    pickle.dump(save_dict,tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"experiments/save/exp1/220728_t20k_r5_hard.pkl\", \"rb\") as handle:\n",
    "    load_dict = pickle.load(handle)\n",
    "    \n",
    "regret_centralized_dict = load_dict['regret_centralized']\n",
    "regret_worst_dict = load_dict['regret_worst']\n",
    "collisions_worst_dict = load_dict['collisions_worst']\n",
    "regret_rsv_dict = load_dict['regret_rsv']\n",
    "collisions_rsv_dict = load_dict['collisions_rsv']\n",
    "regret_cent_stat = load_dict['regret_cent_stat']\n",
    "regret_opt_stat = load_dict['regret_opt_stat']\n",
    "regret_got = load_dict['regret_got']\n",
    "collisions_got = load_dict['collisions_got'] \n",
    "\n",
    "# Run 2 is good\n",
    "# Run 3 is done with non-random server locations\n",
    "# Run 4 should be final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt = len(list(collisions_got))\n",
    "\n",
    "# calculating error bars\n",
    "regret_worst_sd = np.zeros([nt,T])\n",
    "regret_rsv_sd = np.zeros([nt,T])\n",
    "regret_cent_stat_sd = np.zeros([nt,T])\n",
    "regret_got_sd = np.zeros([nt,T])\n",
    "regret_centralized_sd = np.zeros([nt,T])\n",
    "regret_opt_stat_sd = np.zeros([nt,T])\n",
    "collisions_worst_sd = np.zeros([nt,T])\n",
    "collisions_rsv_sd = np.zeros([nt,T])\n",
    "collisions_got_sd = np.zeros([nt,T])\n",
    "\n",
    "\n",
    "for i in range(nt):\n",
    "    regret_worst_sd[i] = np.cumsum(regret_worst_dict[i])\n",
    "    regret_rsv_sd[i] = np.cumsum(regret_rsv_dict[i])\n",
    "    regret_cent_stat_sd[i] = np.cumsum(regret_cent_stat[i])\n",
    "    regret_got_sd[i] = np.cumsum(regret_got[i])\n",
    "    \n",
    "    temp_cavg = regret_centralized_dict[i]\n",
    "    temp_cavg[temp_cavg<0] = 0\n",
    "    regret_centralized_sd[i] = np.cumsum(temp_cavg)\n",
    "    \n",
    "    \n",
    "    regret_opt_stat_sd[i] = np.cumsum(regret_opt_stat[i])\n",
    "    collisions_worst_sd[i] = np.cumsum(collisions_worst_dict[i])\n",
    "    collisions_rsv_sd[i] = np.cumsum(collisions_rsv_dict[i])\n",
    "    collisions_got_sd[i] = np.cumsum(collisions_got[i])\n",
    "    \n",
    "regret_worst_sd2 = np.sqrt(regret_worst_sd.var(0))\n",
    "regret_rsv_sd2 = np.sqrt(regret_rsv_sd.var(0))\n",
    "regret_cent_stat_sd2 = np.sqrt(regret_cent_stat_sd.var(0))\n",
    "regret_got_sd2 = np.sqrt(regret_got_sd.var(0))\n",
    "regret_centralized_sd2 = np.sqrt(regret_centralized_sd.var(0))\n",
    "regret_opt_stat_sd2 = np.sqrt(regret_opt_stat_sd.var(0))\n",
    "collisions_worst_sd2 = np.sqrt(collisions_worst_sd.var(0))\n",
    "collisions_rsv_sd2 = np.sqrt(collisions_rsv_sd.var(0))\n",
    "collisions_got_sd2 = np.sqrt(collisions_got_sd.var(0))\n",
    "\n",
    "\n",
    "# Calculating Mean\n",
    "regret_worst_avg = 1/trials * regret_worst_dict[0]\n",
    "regret_rsv_avg= 1/trials * regret_rsv_dict[0]\n",
    "regret_cent_stat_avg= 1/trials * regret_cent_stat[0]\n",
    "regret_got_avg= 1/trials * regret_got[0]\n",
    "\n",
    "temp_cavg = regret_centralized_dict[0]\n",
    "temp_cavg[temp_cavg<0] = 0\n",
    "regret_centralized_avg= 1/trials * temp_cavg\n",
    "\n",
    "regret_opt_stat_avg= 1/trials * regret_opt_stat[0]\n",
    "collisions_worst_dict_avg= 1/trials * collisions_worst_dict[0]\n",
    "collisions_rsv_dict_avg= 1/trials * collisions_rsv_dict[0]\n",
    "collisions_got_avg= 1/trials * collisions_got[0]\n",
    "\n",
    "for i in range(1, trials):\n",
    "\n",
    "    regret_worst_avg += 1/trials * regret_worst_dict[i]\n",
    "    regret_rsv_avg += 1/trials * regret_rsv_dict[i]\n",
    "    regret_cent_stat_avg += 1/trials * regret_cent_stat[i]\n",
    "    regret_got_avg += 1/trials * regret_got[i]\n",
    "    \n",
    "    \n",
    "    temp_cavg = regret_centralized_dict[i]\n",
    "    temp_cavg[temp_cavg<0] = 0\n",
    "#     regret_centralized_avg= 1/trials * temp_cavg\n",
    "    \n",
    "    regret_centralized_avg += 1/trials * temp_cavg\n",
    "    \n",
    "    \n",
    "    regret_opt_stat_avg += 1/trials * regret_opt_stat[i]\n",
    "    collisions_worst_dict_avg += 1/trials * collisions_worst_dict[i]\n",
    "    collisions_rsv_dict_avg += 1/trials * collisions_rsv_dict[i]\n",
    "    collisions_got_avg += 1/trials * collisions_got[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from palettable.cubehelix import Cubehelix\n",
    "palette = Cubehelix.make(start=1, rotation=-0.5, n=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette.colors\n",
    "coloridx = [0, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.cumsum(regret_centralized_avg)\n",
    "regret_centralized_adj = regret_centralized_avg\n",
    "# regret_centralized_adj[regret_centralized_adj < 0] = 0\n",
    "# y_adj = np.cumsum(regret_centralized_adj)\n",
    "# plt.plot(range(T), y,'-k', label = \"Central Alg.\", color = \"tab:blue\", linewidth=2.5, linestyle='dashdot')\n",
    "# plt.fill_between(range(T), y-regret_centralized_sd2, y+regret_centralized_sd2,\n",
    "#                 alpha=0.2, edgecolor='tab:blue', facecolor='tab:blue', linewidth=1, antialiased=True)\n",
    "\n",
    "plt.figure(figsize=(6, 4), dpi=800)\n",
    "\n",
    "plt.plot(range(T), y,'-k', label = \"Central Alg.\", color = np.divide(palette.colors[0],255), linewidth=2.5, linestyle='dashdot')\n",
    "plt.fill_between(range(T), y-regret_centralized_sd2, y+regret_centralized_sd2,\n",
    "                alpha=0.2, edgecolor='tab:blue', facecolor=np.divide(palette.colors[0],255), linewidth=1, antialiased=True)\n",
    "\n",
    "#  Set Font Size Limitations\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 16}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "\n",
    "plt.title('Cumulative Regret Edge-Alloc:C')\n",
    "plt.xlabel('Rounds')\n",
    "\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4), dpi=80)\n",
    "\n",
    "\n",
    "P_temp = P_collection\n",
    "User_test = User(usr_locs,svr_locs,mu[0],0,\n",
    "              max_dist = max_dist, threshold_dist = 6, self_weight = 1 - 0.85, P = P_temp, ceiling = 1,\n",
    "              sticky_mode = True, kick_mode=True)\n",
    "\n",
    "a = User_test.stationary_loc\n",
    "\n",
    "pm2 = 0.0\n",
    "for i in range(a.shape[0]):\n",
    "    pm2 += a[i]*(1-P_temp[i,i])\n",
    "    \n",
    "# Delta min calc\n",
    "idx = 0\n",
    "reg_threshold = 0.5\n",
    "regret_temp = copy.deepcopy(regret_rsv_dict[idx])\n",
    "regret_temp[regret_temp <= 0] = 30\n",
    "regret_temp[regret_temp <= reg_threshold] = 10\n",
    "regret_temp[collisions_rsv_dict[idx] == 0] = 10\n",
    "delta_min = min(regret_temp)\n",
    "\n",
    "print('dmin', delta_min)\n",
    "\n",
    "# Calculate Lower Bound\n",
    "pm = 0.02\n",
    "po = 0.05\n",
    "constant = delta_min/(po/(pm * 1) + 1)\n",
    "lower_bound = np.arange(T)*constant\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6, 4), dpi=800)\n",
    "#  Set Font Size Limitations\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 16}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "\n",
    "plt.plot(np.cumsum(regret_worst_avg), label = 'Greedy Dist.', color = np.divide(palette.colors[2],255), linewidth=2.5)\n",
    "y = np.cumsum(regret_worst_avg)\n",
    "plt.fill_between(range(T), y-regret_worst_sd2, y+regret_worst_sd2,\n",
    "                alpha=0.2, facecolor=np.divide(palette.colors[2],255), linewidth=1, antialiased=True)\n",
    "\n",
    "plt.plot(np.cumsum(regret_rsv_avg), label = 'Edge-Alloc:D', color = np.divide(palette.colors[4],255), linewidth=2.5)\n",
    "y = np.cumsum(regret_rsv_avg)\n",
    "plt.fill_between(range(T), y-regret_rsv_sd2, y+regret_rsv_sd2,\n",
    "                alpha=0.2, facecolor=np.divide(palette.colors[4],255), linewidth=1, antialiased=True)\n",
    "\n",
    "plt.plot(np.cumsum(regret_cent_stat_avg), label = 'Stat. Central', color = np.divide(palette.colors[6],255), linewidth=2.5, linestyle='dashed')\n",
    "y = np.cumsum(regret_cent_stat_avg)\n",
    "plt.fill_between(range(T), y-regret_cent_stat_sd2, y+regret_cent_stat_sd2,\n",
    "                alpha=0.2, facecolor=np.divide(palette.colors[6],255), linewidth=1, antialiased=True)\n",
    "\n",
    "plt.plot(np.cumsum(regret_got_avg), label = 'Stat. Dist. (GoT)', color = np.divide(palette.colors[6],255), linewidth=2.5)\n",
    "y = np.cumsum(regret_got_avg)\n",
    "plt.fill_between(range(T), y-regret_got_sd2, y+regret_got_sd2,\n",
    "                alpha=0.2, facecolor=np.divide(palette.colors[6],255), linewidth=1, antialiased=True)\n",
    "\n",
    "plt.plot(lower_bound, label = 'Lower Bound Dist.', color = np.divide(palette.colors[0],255), linewidth=2.5, linestyle='dashdot')\n",
    "\n",
    "# plt.plot(np.cumsum(regret_centralized_avg), label = 'central true')\n",
    "# plt.plot(np.cumsum(regret_opt_stat_avg), label = 'stationary optimal')\n",
    "\n",
    "plt.title('Cumulative Regret Distributed Methods')\n",
    "plt.xlabel('Rounds')\n",
    "plt.legend(prop={'size': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4), dpi=800)\n",
    "\n",
    "# plt.plot(np.cumsum(collisions_worst_dict_avg), label = 'Greedy Dist.', color = \"tab:green\", linewidth=2.5)\n",
    "# y = np.cumsum(collisions_worst_dict_avg)\n",
    "# plt.fill_between(range(T), y-collisions_worst_sd2, y+collisions_worst_sd2,\n",
    "#                 alpha=0.2, edgecolor='tab:green', facecolor='tab:green', linewidth=1, antialiased=True)\n",
    "\n",
    "# plt.plot(np.cumsum(collisions_rsv_dict_avg), label = 'Edge-Alloc:D',color = \"tab:red\", linewidth=2.5)\n",
    "# y = np.cumsum(collisions_rsv_dict_avg)\n",
    "# plt.fill_between(range(T), y-collisions_rsv_sd2, y+collisions_rsv_sd2,\n",
    "#                 alpha=0.2, edgecolor='tab:red', facecolor='tab:red', linewidth=1, antialiased=True)\n",
    "\n",
    "# plt.plot(np.cumsum(collisions_got_avg), label = 'Stat. Dist. (GoT)', color = \"tab:orange\", linewidth=2.5)\n",
    "# y = np.cumsum(collisions_got_avg)\n",
    "# plt.fill_between(range(T), y-collisions_got_sd2, y+collisions_got_sd2,\n",
    "#                 alpha=0.2, edgecolor='tab:orange', facecolor='tab:orange', linewidth=1, antialiased=True)\n",
    "\n",
    "plt.plot(np.cumsum(collisions_worst_dict_avg), label = 'Greedy Dist.', color = np.divide(palette.colors[2],255), \n",
    "         linewidth=2.5)\n",
    "y = np.cumsum(collisions_worst_dict_avg)\n",
    "plt.fill_between(range(T), y-collisions_worst_sd2, y+collisions_worst_sd2,\n",
    "                alpha=0.2, facecolor=np.divide(palette.colors[2],255), linewidth=1, antialiased=True)\n",
    "\n",
    "plt.plot(np.cumsum(collisions_rsv_dict_avg), label = 'Edge-Alloc:D',color = np.divide(palette.colors[4],255)\n",
    "         , linewidth=2.5)\n",
    "y = np.cumsum(collisions_rsv_dict_avg)\n",
    "plt.fill_between(range(T), y-collisions_rsv_sd2, y+collisions_rsv_sd2,\n",
    "                alpha=0.2, facecolor=np.divide(palette.colors[4],255), linewidth=1, antialiased=True)\n",
    "\n",
    "plt.plot(np.cumsum(collisions_got_avg), label = 'Stat. Dist. (GoT)', color = np.divide(palette.colors[6],255), linewidth=2.5)\n",
    "y = np.cumsum(collisions_got_avg)\n",
    "plt.fill_between(range(T), y-collisions_got_sd2, y+collisions_got_sd2,\n",
    "                alpha=0.2, facecolor=np.divide(palette.colors[6],255), linewidth=1, antialiased=True)\n",
    "\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "\n",
    "plt.title('Cumulative Collisions Distributed Methods')\n",
    "plt.xlabel('Rounds')\n",
    "plt.legend(prop={'size': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m = 100\n",
    "plt.plot(moving_average(collisions_worst_dict_avg,m), label = 'worst case')\n",
    "plt.plot(moving_average(collisions_rsv_dict_avg,m), label = 'new rsv')\n",
    "plt.plot(moving_average(collisions_got_avg,m), label = 'got')\n",
    "\n",
    "\n",
    "plt.title('Per Round Collisions CMAB')\n",
    "plt.xlabel('Rounds')\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(regret_centralized_dict[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(regret_centralized_dict[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
