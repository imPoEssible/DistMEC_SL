{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/DistMEC\n"
     ]
    }
   ],
   "source": [
    "cd /home/ubuntu/DistMEC/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from classes.User import *\n",
    "from classes.solver import *\n",
    "from classes.Server import *\n",
    "from classes.distributed_utils import *\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from time import sleep\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "regret_rsv_dict_list = []\n",
    "regret_worst_dict_list = []\n",
    "regret_central_dict_list = []\n",
    "regret_cstat_dict_list = []\n",
    "coll_rsv_dict_list = []\n",
    "coll_worst_dict_list = []\n",
    "\n",
    "# System Parameters\n",
    "T = 10000\n",
    "num_users_list = [2,5,10,15,20]\n",
    "num_svrs_list = [2,5,10,15,20]\n",
    "num_locs = 9\n",
    "# mu = np.random.uniform(low=0, high = 1, size = [num_users, num_svrs])\n",
    "ceiling = 40\n",
    "# w = np.random.uniform(low=0, high=1, size= [num_users, num_svrs])\n",
    "space_1d_dim = 10 #4 for small, 10 for big\n",
    "svr_offset_uniform = 2\n",
    "max_dist = 8\n",
    "\n",
    "num_explore = 1\n",
    "trials = 2\n",
    "\n",
    "# result dictionaries\n",
    "result_dicts = []\n",
    "performance_list = []\n",
    "user_dicts = []\n",
    "\n",
    "save_name = 'results/22_06_16_ceiling_20/'\n",
    "isExist = os.path.exists(save_name)\n",
    "if not isExist:\n",
    "  # Create a new directory because it does not exist \n",
    "    os.makedirs(save_name)\n",
    "\n",
    "\n",
    "# Generate visitng locations and server locations\n",
    "usr_locs = gen_eq_locs(space_1d=space_1d_dim, nums=num_locs,offset = 1.7)\n",
    "# svr_locs = gen_eq_locs(space_1d=space_1d_dim, nums=num_svrs,offset = 1.7)\n",
    "\n",
    "with open('traces_P_40k.pkl', 'rb') as handle:\n",
    "    P_collection = pickle.load(handle)\n",
    "    \n",
    "with open('traces_P_40k_dict.pkl', 'rb') as handle:\n",
    "    P_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-5506c345f19b>:88: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for (zzz,t) in zip(tqdm_notebook(range(T-round_start)),range(round_start, T)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae4052b4cf54ecaa3a5c974de4c7860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9997.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8784e72141741a0bbcb5cd92f65c64c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9997.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ca9475f0a34f8bb7feaf36ab565bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9994.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af75222ea1d4475a5074118357b1837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9994.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for zt in range(len(num_svrs_list)):\n",
    "    num_users = num_users_list[zt]\n",
    "    num_svrs = num_svrs_list[zt]\n",
    "    # Recording Mechanism\n",
    "    regret_centralized_dict = {}\n",
    "\n",
    "    regret_worst_dict = {}\n",
    "    collisions_worst_dict = {}\n",
    "\n",
    "    regret_rsv_dict = {}\n",
    "    collisions_rsv_dict = {}\n",
    "\n",
    "    regret_cent_stat = {}\n",
    "    \n",
    "    mu = np.random.uniform(low=0, high = 1, size = [num_users, num_svrs])\n",
    "\n",
    "\n",
    "    for tri in range(trials):\n",
    "\n",
    "        # Build artificial P --> 0.95 Self transition, 0.05/S-1 other transitions\n",
    "        P = np.zeros(P_collection.shape)\n",
    "\n",
    "        temp_pm = 0.05\n",
    "\n",
    "        for i in range(P.shape[0]):\n",
    "            for j in range(P.shape[0]):\n",
    "                if i != j:\n",
    "                    P[i,j] = temp_pm/(P.shape[0]-1)\n",
    "                else:\n",
    "                    P[i,j] = 1-temp_pm\n",
    "\n",
    "\n",
    "        svr_locs = gen_rand_locs(space_1d=space_1d_dim - svr_offset_uniform, nums=num_svrs)\n",
    "#         svr_locs = gen_eq_locs(space_1d=space_1d_dim, nums=num_svrs,offset = 1.7)\n",
    "        # Create Users\n",
    "        Users_w = []\n",
    "        for i in range(num_users):\n",
    "#             P_temp = P_collection\n",
    "            Users_w += [User(usr_locs,svr_locs,mu[i],i,\n",
    "                          max_dist = max_dist, threshold_dist = 6, self_weight = 0.95,\n",
    "                             P = P, ceiling = 1, sticky_mode = True, kick_mode=True)]\n",
    "\n",
    "        # Create Servers\n",
    "        Servers = []\n",
    "        for i in range(num_svrs):\n",
    "            Servers += [Server(svr_locs[i],mu,i)]\n",
    "\n",
    "        # Recorded Values - reservation\n",
    "        regret_g = np.zeros(T) # Got\n",
    "        collision_count_g = np.zeros(T)\n",
    "        optimal_reward_g = np.zeros(T)\n",
    "\n",
    "        regret_w = np.zeros(T) # Worst\n",
    "        collision_count_w = np.zeros(T)\n",
    "        optimal_reward = np.zeros(T)\n",
    "\n",
    "        # Explore rounds are common/shared across all users\n",
    "        explore_rounds(Users_w, num_users, Servers, mu, regret_w, collision_count_w, optimal_reward,\n",
    "                       usr_move_flag = True, rounds=num_explore)\n",
    "\n",
    "        round_start = ((num_svrs)*num_explore)+1\n",
    "\n",
    "\n",
    "        # Other reward recodings\n",
    "        Users_rsv = copy.deepcopy(Users_w)\n",
    "        regret_rsv = copy.deepcopy(regret_w)\n",
    "        collision_count_rsv = copy.deepcopy(collision_count_w)\n",
    "        for u in Users_rsv:\n",
    "            u.sticky_mode = True\n",
    "            u.kick_mode = True #false\n",
    "            u.ceiling = ceiling\n",
    "            u.expected_time_true = u.get_expected_time()\n",
    "#             u.rsv_lower_bound = 8\n",
    "\n",
    "        # Centralized - true w learning\n",
    "        rewards_record_ct, pulls_record_ct, ucb_ct = extract_centralized_case(Users_w, num_users, num_svrs)\n",
    "        regret_ct = copy.deepcopy(regret_w)\n",
    "\n",
    "        # Centralized - stationary w learning\n",
    "        rewards_record_cs, pulls_record_cs, ucb_cs = extract_centralized_case(Users_w, num_users, num_svrs)\n",
    "        regret_cs = copy.deepcopy(regret_w)\n",
    "\n",
    "        # Centralized - stationary w, known mu\n",
    "        w_stat = obtain_w_stationary(Users_w, num_users, num_svrs)\n",
    "        optimal_stat_arms = offline_optimal_action(w_stat,mu)[0]\n",
    "        regret_cst = copy.deepcopy(regret_w)\n",
    "\n",
    "        for (zzz,t) in zip(tqdm_notebook(range(T-round_start)),range(round_start, T)):\n",
    "            w = obtain_w(Users_w, len(Users_w), len(Servers))\n",
    "            optimal = offline_optimal_action(w, mu)\n",
    "            optimal_reward[t] = optimal[1]\n",
    "\n",
    "            # Distributed solution \n",
    "            play_round(Users_w, Servers, mu, regret_w, collision_count_w, \n",
    "                       usr_move_flag = True, debugger = False, reservation_mode = True, optimal =optimal)\n",
    "            play_round(Users_rsv, Servers, mu, regret_rsv, collision_count_rsv, \n",
    "                       usr_move_flag = False, debugger = False, reservation_mode = True, optimal =optimal, t = t)\n",
    "            copy_usr_loc(Users_w, Users_rsv)\n",
    "\n",
    "            # Centralized Solution -  true w learning\n",
    "            ucb_ct = update_ucb(rewards_record_ct, pulls_record_ct, ucb_ct, t, 1)\n",
    "            arms = offline_optimal_action(w, ucb_ct)[0]\n",
    "            rewards_record_ct, pulls_record_ct = pull_super_arm(arms, mu, rewards_record_ct, pulls_record_ct)\n",
    "            regret_ct[t] = optimal[1] - expected_reward(arms, mu, w)\n",
    "\n",
    "            # Centralized Solution -  stationary w learning\n",
    "            ucb_cs = update_ucb(rewards_record_cs, pulls_record_cs, ucb_cs, t, 1)\n",
    "            arms = offline_optimal_action(w_stat, ucb_cs)[0]\n",
    "            rewards_record_cs, pulls_record_cs = pull_super_arm(arms, mu, rewards_record_cs, pulls_record_cs)\n",
    "            regret_cs[t] = optimal[1] - expected_reward(arms, mu, w)\n",
    "\n",
    "\n",
    "        regret_centralized_dict[tri] = copy.deepcopy(regret_ct)\n",
    "\n",
    "        regret_worst_dict[tri] = copy.deepcopy(regret_w)\n",
    "        collisions_worst_dict[tri] = copy.deepcopy(collision_count_w)\n",
    "\n",
    "        regret_rsv_dict[tri] = copy.deepcopy(regret_rsv)\n",
    "        collisions_rsv_dict[tri] = copy.deepcopy(collision_count_rsv)\n",
    "\n",
    "        regret_cent_stat[tri] = copy.deepcopy(regret_cs)\n",
    "#         regret_opt_stat[tri] = copy.deepcopy(regret_cst)\n",
    "\n",
    "\n",
    "        del Users_w, Users_rsv, Servers\n",
    "    regret_rsv_dict_list += [regret_rsv_dict]\n",
    "    regret_worst_dict_list += [regret_worst_dict]\n",
    "    regret_central_dict_list += [regret_centralized_dict]\n",
    "    regret_cstat_dict_list += [regret_cent_stat]\n",
    "    coll_rsv_dict_list += [collisions_rsv_dict]\n",
    "    coll_worst_dict_list += [collisions_worst_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict = {}\n",
    "save_dict['regret_rsv_dict_list'] = regret_rsv_dict_list\n",
    "save_dict['regret_worst_dict_list'] = regret_worst_dict_list\n",
    "save_dict['regret_central_dict_list'] = regret_central_dict_list\n",
    "save_dict['regret_cstat_dict_list'] = regret_cstat_dict_list\n",
    "save_dict['coll_rsv_dict_list'] = coll_rsv_dict_list\n",
    "save_dict['coll_worst_dict_list'] = coll_worst_dict_list\n",
    "\n",
    "with open(\"experiments/save/exp7/220724_run1_t5_dummy.pkl\", \"wb\") as tf:\n",
    "    pickle.dump(save_dict,tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"experiments/save/exp7/220724_run1_t5_dummy.pkl\", \"rb\") as handle:\n",
    "    load_dict = pickle.load(handle)\n",
    "    \n",
    "regret_rsv_dict_list = load_dict['regret_rsv_dict_list']\n",
    "regret_worst_dict_list = load_dict['regret_worst_dict_list']\n",
    "regret_central_dict_list = load_dict['regret_central_dict_list']\n",
    "regret_cstat_dict_list = load_dict['regret_cstat_dict_list']\n",
    "\n",
    "coll_rsv_dict_list = load_dict['coll_rsv_dict_list']\n",
    "coll_worst_dict_list = load_dict['coll_worst_dict_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = usr_mobility_prob\n",
    "regret_rsv_plot = []\n",
    "regret_worst_plot = []\n",
    "regret_central_plot = []\n",
    "regret_cstat_plot = []\n",
    "\n",
    "coll_rsv_plot = []\n",
    "coll_worst_plot = []\n",
    "\n",
    "for zt in range(len(usr_mobility_prob)):\n",
    "    \n",
    "    regret_rsv_avg = 1/trials * regret_rsv_dict_list[zt][0]\n",
    "    regret_worst_avg= 1/trials * regret_worst_dict_list[zt][0]\n",
    "    regret_centralized_avg = 1/trials * regret_central_dict_list[zt][0]\n",
    "    regret_cent_stat_avg= 1/trials * regret_cstat_dict_list[zt][0]\n",
    "    \n",
    "    coll_rsv_avg = 1/trials * coll_rsv_dict_list[zt][0]\n",
    "    coll_worst_avg= 1/trials * coll_worst_dict_list[zt][0]\n",
    "\n",
    "    \n",
    "    for i in range(1, trials):\n",
    "\n",
    "        regret_rsv_avg += 1/trials * regret_rsv_dict_list[zt][i]\n",
    "        regret_worst_avg += 1/trials * regret_worst_dict_list[zt][i]\n",
    "        regret_centralized_avg += 1/trials * regret_central_dict_list[zt][i]\n",
    "        regret_cent_stat_avg += 1/trials * regret_cstat_dict_list[zt][i]\n",
    "        coll_rsv_avg += 1/trials * coll_rsv_dict_list[zt][i]\n",
    "        coll_worst_avg += 1/trials * coll_worst_dict_list[zt][i]\n",
    "    \n",
    "    regret_rsv_plot += [copy.deepcopy(np.cumsum(regret_rsv_avg)[-1])]\n",
    "    regret_worst_plot += [copy.deepcopy(np.cumsum(regret_worst_avg)[-1])]\n",
    "    regret_central_plot += [copy.deepcopy(np.cumsum(regret_centralized_avg)[-1])]\n",
    "    regret_cstat_plot += [copy.deepcopy(np.cumsum(regret_cent_stat_avg)[-1])]\n",
    "    \n",
    "    coll_rsv_plot += [copy.deepcopy(np.cumsum(coll_rsv_avg)[-1])]\n",
    "    coll_worst_plot += [copy.deepcopy(np.cumsum(coll_worst_avg)[-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,coll_rsv_plot, label = 'Reserve Dist.')\n",
    "plt.plot(x,coll_worst_plot, label = 'Greedy Dist.')\n",
    "\n",
    "\n",
    "#  Set Font Size Limitations\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 16}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "\n",
    "plt.title('Cumulative Collision for Different Movement')\n",
    "plt.xlabel('Probability of Mobility Per Round')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
