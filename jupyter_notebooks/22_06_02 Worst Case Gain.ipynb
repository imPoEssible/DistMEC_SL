{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/DistMEC\n"
     ]
    }
   ],
   "source": [
    "cd /home/ubuntu/DistMEC/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from classes.User import *\n",
    "from classes.solver import *\n",
    "from classes.Server import *\n",
    "from classes.distributed_utils import *\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from time import sleep\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_usr_loc(Users1, Users2):\n",
    "    \n",
    "    for u in range(len(Users1)):\n",
    "        Users2[u].usr_place = Users1[u].usr_place\n",
    "        Users2[u].expected_time_true = Users2[u].get_expected_time()\n",
    "        \n",
    "def moving_average(a, n=3) :\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f82492a91e15473e925deb4496087ab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4983), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "trial: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca5e93c6eade410e96929de58ebaef12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4983), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "trial: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b1625253b4400b9d2500474ed2e060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4983), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# System Parameters\n",
    "T = 5000\n",
    "num_users = 10\n",
    "num_svrs = 16\n",
    "num_locs = 16\n",
    "mu = np.random.uniform(low=0, high = 1, size = [num_users, num_svrs])\n",
    "ceiling = 20\n",
    "# w = np.random.uniform(low=0, high=1, size= [num_users, num_svrs])\n",
    "space_1d_dim = 10 #4 for small, 10 for big\n",
    "\n",
    "num_explore = 1\n",
    "trials = 3\n",
    "\n",
    "# result dictionaries\n",
    "result_dicts = []\n",
    "performance_list = []\n",
    "user_dicts = []\n",
    "\n",
    "save_name = 'results/22_06_16_ceiling_20/'\n",
    "isExist = os.path.exists(save_name)\n",
    "if not isExist:\n",
    "  # Create a new directory because it does not exist \n",
    "    os.makedirs(save_name)\n",
    "\n",
    "for tri in range(trials):\n",
    "    \n",
    "    print(\"trial:\", tri)\n",
    "    result_dict = {}\n",
    "    user_dict = {}\n",
    "    \n",
    "    # Generate visitng locations and server locations\n",
    "    usr_locs = gen_eq_locs(space_1d=space_1d_dim, nums=num_locs,offset = 1.7)\n",
    "    svr_locs = gen_eq_locs(space_1d=space_1d_dim, nums=num_svrs,offset = 1.7)\n",
    "\n",
    "    # Create Users\n",
    "    Users = []\n",
    "    for i in range(num_users):\n",
    "        Users += [User(usr_locs,svr_locs,mu[i],i,\n",
    "                      max_dist = 7, threshold_dist = 6, self_weight = 1 - 0.95, P = None, ceiling = ceiling,\n",
    "                      sticky_mode = False, kick_mode=True)]\n",
    "\n",
    "    # Create Servers\n",
    "    Servers = []\n",
    "    for i in range(num_svrs):\n",
    "        Servers += [Server(svr_locs[i],mu,i)]\n",
    "\n",
    "    # Recorded Values - reservation\n",
    "    regret = np.zeros(T)\n",
    "    collision_count = np.zeros(T)\n",
    "    optimal_reward = np.zeros(T)\n",
    "\n",
    "    # Explore rounds are common/shared across all users\n",
    "    explore_rounds(Users, num_users, Servers, mu, regret, collision_count, optimal_reward,\n",
    "                   usr_move_flag = True, rounds=num_explore)\n",
    "\n",
    "    # Make copies of values for worst case\n",
    "    Users_w = copy.deepcopy(Users)\n",
    "    regret_w = copy.deepcopy(regret)\n",
    "    collision_count_w = copy.deepcopy(collision_count)\n",
    "\n",
    "    # For sticky Case\n",
    "    Users_s = copy.deepcopy(Users)\n",
    "    regret_s = copy.deepcopy(regret)\n",
    "    collision_count_s = copy.deepcopy(collision_count)\n",
    "    for u in Users_s:\n",
    "        u.sticky_mode = True\n",
    "        u.kick_mode = True #false\n",
    "\n",
    "    round_start = ((num_svrs)*num_explore)+1\n",
    "    for (zzz,t) in zip(tqdm_notebook(range(T-round_start)),range(round_start, T)):\n",
    "        w = obtain_w(Users, len(Users), len(Servers))\n",
    "        optimal = offline_optimal_action(w, mu)\n",
    "        optimal_reward[t] = optimal[1]\n",
    "        play_round(Users, Servers, mu, regret, collision_count, \n",
    "                   usr_move_flag = True, debugger = False, reservation_mode = True, optimal =optimal)\n",
    "        play_round(Users_w, Servers, mu, regret_w, collision_count_w, \n",
    "                   usr_move_flag = False, debugger=False, reservation_mode = False, optimal=optimal)\n",
    "        play_round(Users_s, Servers, mu, regret_s, collision_count_s, \n",
    "                   usr_move_flag = False, debugger=False, reservation_mode = True, optimal=optimal)\n",
    "        copy_usr_loc(Users, Users_w)\n",
    "        copy_usr_loc(Users, Users_s)\n",
    "\n",
    "    # Obtain reward values\n",
    "    reward = optimal_reward - regret\n",
    "    reward_w = optimal_reward - regret_w\n",
    "    reward_s = optimal_reward - regret_s\n",
    "    threshold = 1\n",
    "\n",
    "    # reward[reward <=  0] = threshold\n",
    "    reward_w[reward_w <= 0] = reward_s[reward_w <=  0]# threshold\n",
    "    \n",
    "    # Log results\n",
    "    result_dict[\"reward_res\"] = reward\n",
    "    result_dict[\"reward_w\"] = reward_w\n",
    "    result_dict[\"reward_s\"] = reward_s\n",
    "    result_dict[\"regret_res\"] = regret\n",
    "    result_dict[\"regret_w\"] = regret_w\n",
    "    result_dict[\"regret_s\"] = regret_s\n",
    "    result_dict[\"collision_res\"] = collision_count\n",
    "    result_dict[\"collision_w\"] = collision_count_w\n",
    "    result_dict[\"collision_s\"] = collision_count_s\n",
    "    \n",
    "    if np.cumsum(regret)[-1] > np.cumsum(regret_s)[-1]:\n",
    "        performance_list += [1]\n",
    "    else:\n",
    "        performance_list += [0]\n",
    "        \n",
    "    # Store values\n",
    "    user_dict['worst'] = Users_w\n",
    "    user_dict['res'] = Users\n",
    "    user_dict['new'] = Users_s\n",
    "    \n",
    "    result_save_name = save_name + 'regret_trial' + str(tri) + '.p'\n",
    "    with open(result_save_name, 'wb') as handle:\n",
    "        pickle.dump(result_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    user_save_name = save_name + 'user_trial' + str(tri) + '.p'\n",
    "    with open(user_save_name, 'wb') as handle:\n",
    "        pickle.dump(user_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    \n",
    "    \n",
    "    user_dicts += [user_dict]\n",
    "    result_dicts += [result_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_idx = 1\n",
    "\n",
    "plt.plot(np.cumsum(result_dicts[plot_idx]['regret_res']), label = 'reserve')\n",
    "plt.plot(np.cumsum(result_dicts[plot_idx]['regret_w']), label = 'worst case')\n",
    "plt.plot(np.cumsum(result_dicts[plot_idx]['regret_s']), label = 'new rsv')\n",
    "plt.title('Cumulative Reward CMAB')\n",
    "plt.xlabel('Rounds')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_idx = 0\n",
    "\n",
    "plt.plot(np.cumsum(result_dicts[plot_idx]['collision_res']), label = 'reserve')\n",
    "plt.plot(np.cumsum(result_dicts[plot_idx]['collision_w']), label = 'worst case')\n",
    "plt.plot(np.cumsum(result_dicts[plot_idx]['collision_s']), label = 'new rsv')\n",
    "plt.title('Cumulative Collisions CMAB')\n",
    "plt.xlabel('Rounds')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_idx = 7\n",
    "\n",
    "# data preprocessing\n",
    "n = 100\n",
    "y1 = np.divide(result_dicts[plot_idx]['reward_res'], result_dicts[plot_idx]['reward_w'])\n",
    "y1 = moving_average(y1,n=n)\n",
    "\n",
    "y2 = np.divide(result_dicts[plot_idx]['reward_s'], result_dicts[plot_idx]['reward_w'])\n",
    "y2 = moving_average(y2, n=n)\n",
    "\n",
    "plt.plot(y1, label = 'regular')\n",
    "plt.plot(y2, label = 'new')\n",
    "plt.title('Reward Proportion to Worst Case CMAB')\n",
    "plt.xlabel('Rounds')\n",
    "plt.ylabel('Reward')\n",
    "plt.legend()\n",
    "\n",
    "print('reg',np.mean(np.divide(reward, reward_w)))\n",
    "print('new',np.mean(np.divide(reward_s, reward_w)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_idx = 7\n",
    "\n",
    "m = 50\n",
    "plt.plot(moving_average(result_dicts[plot_idx]['collision_res'],m), label = 'reserve')\n",
    "plt.plot(moving_average(result_dicts[plot_idx]['collision_w'],m), label = 'worst case')\n",
    "plt.plot(moving_average(result_dicts[plot_idx]['collision_s'],m), label = 'new rsv')\n",
    "plt.title('Per Round Collisions CMAB')\n",
    "plt.xlabel('Rounds')\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make plots of average\n",
    "b = result_dicts\n",
    "\n",
    "regret_res_avg = np.zeros(T)\n",
    "regret_w_avg = np.zeros(T)\n",
    "regret_s_avg = np.zeros(T)\n",
    "\n",
    "for i in range(trials):\n",
    "    regret_res_avg += 1/trials * b[i]['regret_res']\n",
    "    regret_w_avg += 1/trials * b[i]['regret_w']\n",
    "    regret_s_avg += 1/trials * b[i]['regret_s']\n",
    "\n",
    "plt.plot(np.cumsum(regret_res_avg), label = 'reserve')\n",
    "plt.plot(np.cumsum(regret_w_avg), label = 'worst case')\n",
    "plt.plot(np.cumsum(regret_s_avg), label = 'new rsv')\n",
    "plt.title('Cumulative Regret CMAB')\n",
    "plt.xlabel('Rounds')\n",
    "plt.ylabel('Regret')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make plots of average\n",
    "b = result_dicts\n",
    "T = 5000\n",
    "trials = 3\n",
    "\n",
    "regret_res_avg = np.zeros(T)\n",
    "regret_w_avg = np.zeros(T)\n",
    "regret_s_avg = np.zeros(T)\n",
    "\n",
    "for i in range(trials):\n",
    "    regret_res_avg += 1/trials * b[i]['collision_res']\n",
    "    regret_w_avg += 1/trials * b[i]['collision_w']\n",
    "    regret_s_avg += 1/trials * b[i]['collision_s']\n",
    "\n",
    "plt.plot(np.cumsum(regret_res_avg), label = 'reserve')\n",
    "plt.plot(np.cumsum(regret_w_avg), label = 'worst case')\n",
    "plt.plot(np.cumsum(regret_s_avg), label = 'new rsv')\n",
    "plt.title('Cumulative Collision CMAB')\n",
    "plt.xlabel('Rounds')\n",
    "plt.ylabel('Regret')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials_load = 5\n",
    "result_dicts = []\n",
    "user_dicts = []\n",
    "# Load pre-saved data to analyze\n",
    "name = 'results/fixed_bug_t2/regret_trial'\n",
    "name_u = 'results/fixed_bug_t2/user_trial'\n",
    "for i in range(num_trials_load):\n",
    "    name2 = name + str(i) + '.p'\n",
    "    name3 = name_u + str(i) + '.p'\n",
    "    \n",
    "    with open(name2, 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "    result_dicts += [b]\n",
    "    \n",
    "    with open(name3, 'rb') as handle:\n",
    "        c = pickle.load(handle)\n",
    "    user_dicts += [c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(result_dicts[0]['collision_s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(user_dicts[0]['new'][0].history_reserve)/5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
