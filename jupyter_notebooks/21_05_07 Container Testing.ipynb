{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Container Testing\n",
    "\n",
    "Date: 5.7.21\n",
    "\n",
    "Summary: Test the container class with the following characteristics:\n",
    "\n",
    "- FCFS Queue\n",
    "- Returning latency feedback to users\n",
    "- Queues carry on between small timesteps\n",
    "- Queues flush and reset between big timesteps\n",
    "- Compatibility with central controller deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tkim/Academics/DistMEC\n"
     ]
    }
   ],
   "source": [
    "cd /home/tkim/Academics/DistMEC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from classes.Application import *\n",
    "from classes.User import *\n",
    "from classes.Server import *\n",
    "from solver.Sim_Params import *\n",
    "import copy\n",
    "# from classes.Central_Controller import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Container Class\n",
    "\n",
    "Build the class here and import to .py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Application:\n",
    "    \"\"\"\n",
    "    Job: Associated with each user id and define\n",
    "    - Job type, resource requirements, UE requirements, arrival, departure times\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, job_type, user_id, time_steps, job_profiles):\n",
    "        \"\"\"\n",
    "        job_type - integer [0,1,2] based on the sample profiles we have \n",
    "        user_id - associate job with user id\n",
    "        \"\"\"\n",
    "        \n",
    "        # Init values\n",
    "        self.user_id = user_id\n",
    "        self.job_type = job_type\n",
    "        self.time_steps = time_steps\n",
    "        self.job_profile = job_profiles[job_type] # Load rate, latency restriction      \n",
    "       \n",
    "        # Load latency/offload values\n",
    "        self.latency_req = self.job_profile.latency_req\n",
    "        self.offload_mean = self.job_profile.offload_mean\n",
    "        \n",
    "        # Record total amount of load generated per ts\n",
    "        self.load_history = np.zeros(time_steps)\n",
    "        \n",
    "        # Record Reinforcement learning values below (UCB, confidence range)\n",
    "        \n",
    "        \n",
    "        # Keep information on where relevant VM is\n",
    "        \n",
    "    def new_load(self,t):\n",
    "        \"\"\"\n",
    "        Return a load value for this timestep based on exponential distribution value\n",
    "        This will be logged into the \n",
    "        \"\"\"\n",
    "        \n",
    "        self.load_history[t] =  np.random.exponential(1/self.offload_mean)\n",
    "        return\n",
    "\n",
    "    def cmab_round(self, arm_idx, arm_info, t):\n",
    "        \"\"\"\n",
    "        Run CMAB to select how much load to offload to each arm\n",
    "        \"\"\"\n",
    "        \n",
    "        return\n",
    "        \n",
    "\n",
    "class Job_Profile:\n",
    "    \"\"\"\n",
    "    Make list of job profiles with\n",
    "    - UE properties (how much to offload generated per small ts)\n",
    "    - Length Properties\n",
    "    - Resource Consumption\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, job_name,\n",
    "                    latency_req,\n",
    "                    offload_mean):\n",
    "        \"\"\"\n",
    "        Add job profile to list \n",
    "        \"\"\"\n",
    "        \n",
    "        self.job_name = job_name\n",
    "        self.latency_req = latency_req # milisecond\n",
    "        self.offload_mean = offload_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Container:\n",
    "    \"\"\"\n",
    "    Container: Associated with a specific server-application pair for one-to-many matching\n",
    "    Here \n",
    "    - Job type, resource requirements, UE requirements, arrival, departure times\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, app_id, server_id, service_rate, latency_restriction):\n",
    "        \"\"\"\n",
    "        app_id - which application this container is for\n",
    "        server_id - which server this VM is designated for (binary on off)\n",
    "        \"\"\"\n",
    "        \n",
    "        self.app_id = app_id\n",
    "        self.server_id = server_id\n",
    "        self.deployed = False # True when active at server\n",
    "        self.service_rate = service_rate\n",
    "        self.latency_restriction = latency_restriction\n",
    "        \n",
    "        # queue --> [user_id, ts_arrive, load, remaining load]\n",
    "        self.queue = np.empty((0,4))\n",
    "        # history --> [user_id,ts_arrive,load,completion_time]\n",
    "        self.history = np.empty((0,4))\n",
    "        \n",
    "    def add_to_queue(self, new_offload):\n",
    "        \"\"\"\n",
    "        At the start of small TS add all queues\n",
    "        new_offload -> np array of shape (1,3)\n",
    "        \"\"\"\n",
    "        \n",
    "        num_jobs = new_offload.shape[0]\n",
    "        \n",
    "        # Add new arrival information\n",
    "        self.queue = np.append(self.queue,new_offload,axis=0)\n",
    "        # Compute run time for each job\n",
    "        loads = self.queue[:,3]\n",
    "        load_cm = np.cumsum(loads)\n",
    "        service_time = (load_cm/self.service_rate)[-num_jobs:]\n",
    "        \n",
    "        # Add to history\n",
    "        new_history = copy.deepcopy(new_offload)\n",
    "        new_history[:,3] = service_time\n",
    "        \n",
    "        self.history = np.append(self.history, new_history,axis=0)\n",
    "        \n",
    "        service_time_log = np.append(new_history[:,0].reshape(new_history[:,0].shape[0],1),\n",
    "                                     service_time.reshape(service_time.shape[0],1),axis=1)\n",
    "        \n",
    "        return service_time_log\n",
    "    \n",
    "    def serve_ts(self):\n",
    "        \"\"\"\n",
    "        subtract from queue based on the existing service rate\n",
    "        Update self.queue and whatever remains\n",
    "        \"\"\"\n",
    "        \n",
    "        remaining_service = copy.deepcopy(self.service_rate)\n",
    "        while remaining_service > 0:\n",
    "            remainder = self.queue[0,3]\n",
    "            if remainder <= remaining_service:\n",
    "                self.queue = np.delete(self.queue,0,0)\n",
    "            elif remainder > remaining_service:\n",
    "                self.queue[0,3] = remainder - remaining_service\n",
    "            \n",
    "            remaining_service -= remainder\n",
    "        \n",
    "        return\n",
    "        \n",
    "    def calc_emp_beta(self):\n",
    "        \"\"\"\n",
    "        Calculate the emprical value of beta based on latency violations\n",
    "        \"\"\"\n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Scenarios\n",
    "\n",
    "1. generate containers, add to queue from user, process queue and return information to user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4. , 0.2],\n",
       "       [2. , 0.6],\n",
       "       [3. , 0.9],\n",
       "       [1. , 1. ],\n",
       "       [0. , 1.4]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate container and add jobs\n",
    "j = 5\n",
    "\n",
    "a = Container(app_id = 1, server_id = 1, service_rate = 10, latency_restriction=1)\n",
    "\n",
    "offload = np.empty((0,4))\n",
    "\n",
    "for i in range(j):\n",
    "    load = np.random.randint(1,5,1)\n",
    "    new_offload = np.array([[i,0,load,load]])\n",
    "    offload = np.append(offload, new_offload, axis = 0)\n",
    "\n",
    "np.random.shuffle(offload) \n",
    "    \n",
    "val = a.add_to_queue(offload)\n",
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 4., 4.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.serve_ts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4. , 0. , 2. , 0.2],\n",
       "       [2. , 0. , 4. , 0.6],\n",
       "       [3. , 0. , 3. , 0.9],\n",
       "       [1. , 0. , 1. , 1. ],\n",
       "       [0. , 0. , 4. , 1.4]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
